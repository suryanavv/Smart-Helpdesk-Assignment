Assignment: Smart Helpdesk with Agentic
Triage
Goal: Build an endâ€‘toâ€‘end web application where users raise support tickets and an AI
coworker (agentic workflow) triages them by classifying, fetching relevant knowledgeâ€‘base (KB)
articles, drafting a reply, and either autoâ€‘resolving or assigning to a human. You may do this as
MERNâ€‘only (Node orchestrator) or MERN + Python (FastAPI worker). You are free to use your
favourite vibe coding techniques.
Timebox: 48 hours recommended for takeâ€‘home + 60â€“90 min live review.
What weâ€™re evaluating (the â€œvibeâ€):
â— Thoughtful architecture & boundaries; clean, readable code; small, purposeful commits.
â— Problemâ€‘solving clarity; pragmatic tradeâ€‘offs; testing mindset; docs & DX.
â— Secure defaults; resilience (retries/timeouts/idempotency); observability (logs/trace).
â— UI craft: fast, simple, accessible; good empty/error/loading states.
â— Agentic reasoning: tool selection, planning, safe prompting/guardrails, fallbacks.
â— How you can use AI in your development process.
User Stories
Roles:
â— End User: creates tickets, views status and agent replies.
â— Support Agent: reviews triage, edits/drafts final reply, resolves tickets.
â— Admin: manages KB articles; sets agent thresholds (confidence, autoâ€‘close toggle).
Core flows:

1. Auth & Roles: Sign up / sign in with JWT; roleâ€‘based access (Admin/Agent/User).
2. KB Management (Admin): CRUD articles (title, body, tags); publish/unpublish.
3. Ticket Lifecycle (User): Create ticket (title, description, category optional, attachments
   by URL). See timeline of actions.
4. Agentic Triage (System): On new ticket:
   â—‹ Classify category (billing / tech / shipping / other).
   â—‹ Retrieve top KB articles (keyword search minimum; embedding/vector optional).
   â—‹ Draft a suggested reply with citations to KB.
   â—‹ Compute a confidence score (0â€“1). If auto_close on and score â‰¥ threshold,
   autoâ€‘reply & close; else assign to a human.
   â—‹ Log each step (trace id) to an Audit Log visible in UI.
5. Agent Review (Support Agent): Accept/edit draft, send reply, reopen/close ticket.
6. Notifications: Emit an inâ€‘app notification and/or email stub on status change.
   Stretch flows (pick any 1â€“2):
   â— Realâ€‘time updates via WebSocket/Serverâ€‘Sent Events.
   â— SLA checks: mark breach if not responded in X hours; nightly job.
   â— Feedback loop: thumbs up/down on AI reply; retrainable prompts config.
   â— Attachments: extract simple text from .txt/.md URLs and include in triage.
   Track Options
   Track A â€” MERN Only (Agent in Node)
   â— Frontend: React + Vite + (Context/Zustand/Redux), React Router. Tailwind optional.
   â— Backend: Node 20+ / Express + Mongoose (MongoDB Atlas/local). Background
   processing via inâ€‘process queue or BullMQ (Redis) if you prefer.
   â— Agentic logic: Implement the workflow in Node. LLM calls optional; provide a
   deterministic stub (below) to avoid requiring API keys.
   Track B â€” MERN + Python (Agent Worker)
   â— Frontend: Same as Track A.
   â— Backend: Node/Express is the API gateway & persistence layer; publish triage jobs to a
   queue (Redis) or HTTP to Python.
   â— Agent Worker (Python): FastAPI + Pydantic + (Celery/RQ optional) for async tasks.
   Implement LLM calls or deterministic stub. Return structured JSON back to Node.
   LLM Usage: If you have a key (e.g., OpenAI), you may use it via environment vars.
   If not, the stub must fully work and be testable. Prompts must be in code or a
   .prompt.md file.
   Data Model (suggested)
   User
   â— \_id, name, email (unique), password_hash, role in {admin, agent, user},
   createdAt.
   Article (KB)
   â— \_id, title, body, tags: string[], status in {draft, published}, updatedAt.
   Ticket
   â— \_id, title, description, category in {billing, tech, shipping, other},
   status in {open, triaged, waiting_human, resolved, closed}, createdBy,
   assignee, agentSuggestionId?, createdAt, updatedAt.
   AgentSuggestion
   â— \_id, ticketId, predictedCategory, articleIds: string[], draftReply,
   confidence: number, autoClosed: boolean, modelInfo (provider, model,
   promptVersion, latencyMs), createdAt.
   AuditLog
   â— \_id, ticketId, traceId, actor in {system, agent, user}, action (e.g.,
   TICKET_CREATED, AGENT_CLASSIFIED, KB_RETRIEVED, DRAFT_GENERATED,
   AUTO_CLOSED, ASSIGNED_TO_HUMAN, REPLY_SENT), meta (JSON), timestamp.
   Config
   â— \_id, autoCloseEnabled: boolean, confidenceThreshold: number (0â€“1),
   slaHours: number.
   API (minimum)
   Auth
   â— POST /api/auth/register â†’ {token}
   â— POST /api/auth/login â†’ {token}
   KB
   â— GET /api/kb?query=... (search title/body/tags)
   â— POST /api/kb (admin)
   â— PUT /api/kb/:id (admin)
   â— DELETE /api/kb/:id (admin)
   Tickets
   â— POST /api/tickets (user)
   â— GET /api/tickets (filter by status/my tickets)
   â— GET /api/tickets/:id
   â— POST /api/tickets/:id/reply (agent) â†’ change status
   â— POST /api/tickets/:id/assign (admin/agent)
   Agent
   â— POST /api/agent/triage (internal) â†’ enqueues triage for a ticket
   â— GET /api/agent/suggestion/:ticketId
   Config
   â— GET /api/config / PUT /api/config (admin)
   Audit
   â— GET /api/tickets/:id/audit
   You may add endpoints; keep them RESTful, versioned if you like (/api/v1). Use
   proper HTTP status codes.
   Agentic Workflow (required steps)
7. Plan: Build a small planner that decides the steps given a ticket (classification â†’
   retrieval â†’ drafting â†’ decision). Hardcode the plan or encode as a simple state
   machine.
8. Classify: Use a prompt or ruleâ€‘based keywords (deterministic stub allowed). Output
   schema:
   { "predictedCategory": "billing|tech|shipping|other", "confidence": 0.0 }
9. Retrieve KB: At least keyword search (simple regex/BM25/TFâ€‘IDF). Return top 3 article
   IDs with snippet scores.
10. Draft Reply: Compose a short answer with numbered references to the selected KB
    articles. Output schema:
    { "draftReply": "...", "citations": ["<articleId>", "<articleId>"] }
11. Decision: If autoCloseEnabled and confidence â‰¥ threshold â†’ store
    suggestion, create agent reply, mark ticket resolved, log AUTO_CLOSED. Else mark
    waiting_human and assign to a human.
12. Logging: Every step must append an AuditLog event with a traceId (UUID)
    consistent across the pipeline.
    Deterministic LLM Stub (must include):
    â— Implement LLMProvider with an interface classify(text), draft(text,
    articles).
    â— Provide a STUB_MODE=true env so we can run without keys. The stub should:
    â—‹ Classify by simple heuristics (words: â€œrefund/invoiceâ€â†’billing,
    â€œerror/bug/stackâ€â†’tech, â€œdelivery/shipmentâ€â†’shipping, else other) and generate
    a pseudo confidence based on keyword matches.
    â—‹ Draft a templated reply inserting KB titles.
    Frontend Requirements
    â— Pages: Login/Register; KB List+Editor (admin only); Ticket List; Ticket Detail
    (conversation thread + agent suggestion + audit timeline); Settings (config).
    â— State: Keep auth token securely; show roleâ€‘based menus.
    â— UX: Clear CTAs; loading skeletons; error toasts; form validation; responsive layout.
    â— Nice to have: Search & filters; optimistic updates; accessible components (keyboard
    nav, ARIA labels).
    Security & Reliability
    â— Donâ€™t log secrets. Never return stack traces to clients.
    â— Input validation (e.g., Zod/Joi) on all POST/PUT.
    â— JWT with expiry & refresh or shortâ€‘lived access + refresh.
    â— Rate limit auth & mutation endpoints. CORS configured narrowly.
    â— Timeouts for agent calls; retry with backoff; idempotency key for triage jobs.
    Observability
    â— Structured logs (JSON) with traceId & ticketId where relevant.
    â— Basic request logging middleware (method, path, latency, status).
    â— Expose /healthz and /readyz.
    DevOps (minimum viable)
    â— Docker Compose with services: client, api, mongo, (agent, redis if Track B or
    BullMQ).
    â— Oneâ€‘command run: docker compose up.
    â— Seed script to insert sample users, KB articles, and tickets.
    Testing
    â— Backend: At least 5 tests (Jest/Vitest) covering: auth, KB search, ticket create, agent
    triage decision, audit logging.
    â— Frontend: At least 3 tests (Vitest/RTL) for rendering + form validation.
    â— Fixtures: Provide JSON fixtures for stubbed LLM outputs and seed data.
    â— Postman/Thunder tests (optional): Include a collection.
    Acceptance Criteria (we will verify)
13. Can register/login and create a ticket as a normal user.
14. Creating a ticket triggers triage; an AgentSuggestion is persisted.
15. If confidence â‰¥ threshold and autoâ€‘close is on, ticket is moved to resolved with agent
    reply appended; user sees the reply.
16. If below threshold, ticket becomes waiting_human; an agent can open the ticket,
    review the draft, edit, and send.
17. Audit timeline shows ordered steps with timestamps and traceId.
18. KB search returns relevant articles for simple queries.
19. App runs with STUB_MODE=true and no external keys.
20. docker compose up brings the stack up; clear README with envs and seed steps.
    Deliverables
    â— Source code in a public/private repo.
    â— README with:
    â—‹ Architecture diagram + brief rationale.
    â—‹ Setup (env vars, Docker, seed) & run instructions.
    â—‹ How agent works (plan, prompts, tools) & guardrails.
    â—‹ Testing instructions & coverage summary.
    â— Short Loom/video (â‰¤5 min) walkthrough: KB add, ticket create, triage, resolution.
    â— A public url deployed on your favorite cloud like v0.
    Scoring Rubric (100 points)
    â— Core functionality & correctness â€“ 30
    â— Code quality (structure, naming, modularity) â€“ 15
    â— Data modeling & API design â€“ 10
    â— UI/UX (clarity, states, accessibility basics) â€“ 10
    â— Testing (breadth + meaningful assertions) â€“ 10
    â— Agentic workflow design (planning, tools, guardrails, logs) â€“ 15
    â— Security & reliability (validation, rate limits, retries) â€“ 5
    â— DevOps & DX (Docker, scripts, README) â€“ 5
    Disqualifiers: committed secrets; cannot run locally; failing build; no README.
    Antiâ€‘Cheat & Review Plan
    â— Require a short Loom demo and commit history across the timebox.
    â— 60â€“90 min live review: ask to add a small feature (e.g., change confidence threshold
    logic to use perâ€‘category threshold) and fix a seeded bug.
    â— Randomize 2â€“3 KB articles/tickets at review time to check adaptability.
    Starter Seed (example)
    Env (example)
    PORT=8080
    MONGO_URI=mongodb://mongo:27017/helpdesk
    JWT_SECRET=change-me
    AUTO_CLOSE_ENABLED=true
    CONFIDENCE_THRESHOLD=0.78
    STUB_MODE=true
    OPENAI_API_KEY= # optional
    KB Seed (abbrev)
    [
    {"title":"How to update payment
    method","body":"...","tags":["billing","payments"],"status":"published"},
    {"title":"Troubleshooting 500 errors","body":"...","tags":["tech","errors"],"status":"published"},
    {"title":"Tracking your shipment","body":"...","tags":["shipping","delivery"],"status":"published"}
    ]
    Ticket Seed (abbrev)
    [
    {"title":"Refund for double charge","description":"I was charged twice for order
    #1234","category":"other"},
    {"title":"App shows 500 on login","description":"Stack trace mentions auth
    module","category":"other"},
    {"title":"Where is my package?","description":"Shipment delayed 5 days","category":"other"}
    ]
    Hints & Gotchas
    â— Keep prompts and stub rules versioned; include promptVersion in modelInfo.
    â— Avoid leaky abstractions: separate agent from kb and tickets services.
    â— Immutability for audit events; donâ€™t rewrite history.
    â— Be explicit about timezones, ISO timestamps.
    Optional Extras (pick any)
    â— Simple RAG: store TFâ€‘IDF vectors or call a local embedding model; fall back to keyword
    search.
    â— Feature flags for autoCloseEnabled and perâ€‘category thresholds.
    â— Export audit logs as NDJSON.
    â— Minimal roleâ€‘based UI tests with Playwright.
    Submission Checklist
    What great submissions usually show
    â— Clarity over cleverness; simple patterns that scale.
    â— Guardrails around LLMs: input/output schemas, max tokens, temperature, system
    prompts, refusal handling.
    â— Developer empathy: fast local setup, meaningful errors, seed data, fixtures.
    Good luck â€” have fun building your agentic helpdesk! ğŸš€
